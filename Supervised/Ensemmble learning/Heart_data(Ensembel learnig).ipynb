{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "767189aa-f604-4da9-b9a0-70bd9df6361c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging with DecisionTreeClassifier Accuracy: 0.8361\n",
      "Bagging with SVC Accuracy: 0.8689\n",
      "Boosting (Gradient Boosting) Accuracy: 0.7869\n",
      "Boosting (AdaBoost with Decision Tree) Accuracy: 0.8197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\miniconda3\\envs\\machine_learning\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting (Hard) Accuracy: 0.8525\n",
      "Voting (Soft) Accuracy: 0.8852\n",
      "Stacking (Meta-Learner Logistic Regression) Accuracy: 0.8525\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier, AdaBoostClassifier, StackingClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Heart Disease dataset\n",
    "url = \"heart.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Preprocessing: Separate features and target\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the dataset\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Helper function to evaluate models and print accuracy\n",
    "def evaluate_model(model, X_test, y_test, model_name=\"Model\"):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{model_name} Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Bagging: Multiple models in Bagging\n",
    "# -------------------------------\n",
    "base_models = [DecisionTreeClassifier(), SVC(probability=True)]\n",
    "for base_model in base_models:\n",
    "    bagging_clf = BaggingClassifier(estimator=base_model, n_estimators=100, random_state=42)\n",
    "    bagging_clf.fit(X_train, y_train)\n",
    "    evaluate_model(bagging_clf, X_test, y_test, model_name=f\"Bagging with {base_model.__class__.__name__}\")\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Boosting: Gradient Boosting and AdaBoost with different base models\n",
    "# -------------------------------\n",
    "# Gradient Boosting\n",
    "boosting_clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "boosting_clf.fit(X_train, y_train)\n",
    "evaluate_model(boosting_clf, X_test, y_test, model_name=\"Boosting (Gradient Boosting)\")\n",
    "\n",
    "# AdaBoost\n",
    "adaboost_clf = AdaBoostClassifier(estimator=DecisionTreeClassifier(), n_estimators=100, random_state=42)\n",
    "adaboost_clf.fit(X_train, y_train)\n",
    "evaluate_model(adaboost_clf, X_test, y_test, model_name=\"Boosting (AdaBoost with Decision Tree)\")\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Voting: Hard and Soft Voting with multiple models\n",
    "# -------------------------------\n",
    "voting_estimators = [\n",
    "    ('lr', LogisticRegression()),\n",
    "    ('rf', RandomForestClassifier()),\n",
    "    ('svc', SVC(probability=True))\n",
    "]\n",
    "\n",
    "# Hard Voting\n",
    "voting_clf_hard = VotingClassifier(estimators=voting_estimators, voting='hard')\n",
    "voting_clf_hard.fit(X_train, y_train)\n",
    "evaluate_model(voting_clf_hard, X_test, y_test, model_name=\"Voting (Hard)\")\n",
    "\n",
    "# Soft Voting\n",
    "voting_clf_soft = VotingClassifier(estimators=voting_estimators, voting='soft')\n",
    "voting_clf_soft.fit(X_train, y_train)\n",
    "evaluate_model(voting_clf_soft, X_test, y_test, model_name=\"Voting (Soft)\")\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Stacking: Using multiple models in stacking\n",
    "# -------------------------------\n",
    "stacking_estimators = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('svc', SVC(probability=True)),\n",
    "    ('dt', DecisionTreeClassifier())\n",
    "]\n",
    "\n",
    "# Meta learner: Logistic Regression\n",
    "stacking_clf = StackingClassifier(estimators=stacking_estimators, final_estimator=LogisticRegression())\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "evaluate_model(stacking_clf, X_test, y_test, model_name=\"Stacking (Meta-Learner Logistic Regression)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb86294c-3924-462e-b8a1-9d7a8d4507c1",
   "metadata": {},
   "source": [
    "### Dataset Features for house \n",
    "\n",
    "The dataset contains features like median income, house age, rooms, population, and house prices for housing blocks.\n",
    "\n",
    "| **Feature**   | **Description**                  |\n",
    "|---------------|----------------------------------|\n",
    "| `MedInc`      | Median income in the block       |\n",
    "| `HouseAge`    | Median house age in the block    |\n",
    "| `AveRooms`    | Average number of rooms per house|\n",
    "| `AveBedrms`   | Average number of bedrooms       |\n",
    "| `Population`  | Block population                 |\n",
    "| `AveOccup`    | Average house occupancy          |\n",
    "| `Latitude`    | Latitude of the block            |\n",
    "| `Longitude`   | Longitude of the block           |\n",
    "| `Price`       | Median house value (Target)      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186d3a8c-f803-4c32-9541-8680fcc34bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging with DecisionTreeRegressor R^2 Score: 0.8048, MSE: 0.2557\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, BaggingRegressor, AdaBoostRegressor, StackingRegressor, VotingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "# Load the Heart Disease dataset\n",
    "url = \"house_data.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Preprocessing: Separate features and target\n",
    "X = df.drop('Price', axis=1)\n",
    "y = df['Price']\n",
    "\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the dataset\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Helper function to evaluate models and print R^2 and MSE\n",
    "def evaluate_model(model, X_test, y_test, model_name=\"Model\"):\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"{model_name} R^2 Score: {r2:.4f}, MSE: {mse:.4f}\")\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Bagging: Multiple models in Bagging\n",
    "# -------------------------------\n",
    "base_models = [DecisionTreeRegressor(), SVR()]\n",
    "for base_model in base_models:\n",
    "    bagging_clf = BaggingRegressor(estimator=base_model, n_estimators=100, random_state=42)\n",
    "    bagging_clf.fit(X_train, y_train)\n",
    "    evaluate_model(bagging_clf, X_test, y_test, model_name=f\"Bagging with {base_model.__class__.__name__}\")\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Boosting: Gradient Boosting and AdaBoost with different base models\n",
    "# -------------------------------\n",
    "# Gradient Boosting\n",
    "boosting_clf = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "boosting_clf.fit(X_train, y_train)\n",
    "evaluate_model(boosting_clf, X_test, y_test, model_name=\"Boosting (Gradient Boosting)\")\n",
    "\n",
    "# AdaBoost\n",
    "adaboost_clf = AdaBoostRegressor(estimator=DecisionTreeRegressor(), n_estimators=100, random_state=42)\n",
    "adaboost_clf.fit(X_train, y_train)\n",
    "evaluate_model(adaboost_clf, X_test, y_test, model_name=\"Boosting (AdaBoost with Decision Tree)\")\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Voting: Hard and Soft Voting with multiple models\n",
    "# -------------------------------\n",
    "voting_estimators = [\n",
    "    ('lr', LinearRegression()),\n",
    "    ('rf', RandomForestRegressor()),\n",
    "    ('svr', SVR())\n",
    "]\n",
    "\n",
    "# Voting Regressor (no hard/soft distinction here, just averaged predictions)\n",
    "voting_clf = VotingRegressor(estimators=voting_estimators)\n",
    "voting_clf.fit(X_train, y_train)\n",
    "evaluate_model(voting_clf, X_test, y_test, model_name=\"Voting Regressor\")\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Stacking: Using multiple models in stacking\n",
    "# -------------------------------\n",
    "stacking_estimators = [\n",
    "    ('rf', RandomForestRegressor(n_estimators=100, random_state=42)),\n",
    "    ('svr', SVR()),\n",
    "    ('dt', DecisionTreeRegressor())\n",
    "]\n",
    "\n",
    "# Meta learner: Linear Regression\n",
    "stacking_clf = StackingRegressor(estimators=stacking_estimators, final_estimator=LinearRegression())\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "evaluate_model(stacking_clf, X_test, y_test, model_name=\"Stacking (Meta-Learner Linear Regression)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e979a60-07da-4339-8c35-306d700d12ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, BaggingRegressor, AdaBoostRegressor, StackingRegressor, VotingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "# Load the Heart Disease dataset\n",
    "url = \"house_data.csv\"\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05657d0c-c390-4826-9360-da6aa80b1876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup',\n",
       "       'Latitude', 'Longitude', 'Price'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c859e35b-6e85-4141-a678-99828ad49537",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
